{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f84ddd4",
   "metadata": {},
   "source": [
    "### Webscraping :- \n",
    "* https://realpython.com/python-web-scraping-practical-introduction/\n",
    "* It is the process of collecting and parsing data from the Web, and the Python community has come up with some pretty powerful web scarpping tools.\n",
    "* One useful package for web scraping that you can find in Python’s standard library is urllib, which contains tools for working with URLs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fe776a",
   "metadata": {},
   "source": [
    "### Using String methods "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8de1d0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<http.client.HTTPResponse at 0x7f6ad8f7ab90>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 1:-\n",
    "from urllib.request import urlopen\n",
    "url = \"http://olympus.realpython.org/profiles/aphrodite\"\n",
    "page=urlopen(url) #  urlopen() returns an HTTPResponse object\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09593bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      "<head>\n",
      "<title>Profile: Aphrodite</title>\n",
      "</head>\n",
      "<body bgcolor=\"yellow\">\n",
      "<center>\n",
      "<br><br>\n",
      "<img src=\"/static/aphrodite.gif\" />\n",
      "<h2>Name: Aphrodite</h2>\n",
      "<br><br>\n",
      "Favorite animal: Dove\n",
      "<br><br>\n",
      "Favorite color: Red\n",
      "<br><br>\n",
      "Hometown: Mount Olympus\n",
      "</center>\n",
      "</body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "html_bytes=page.read() # read() - to read the HTTPReponse object into bytes, provided by HTTPResponse \n",
    "html_decode=html_bytes.decode('utf-8') # decode()- to convert bytes to UTF-8 \n",
    "print(html_decode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83d35573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(html_decode)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef286f7",
   "metadata": {},
   "source": [
    "#### Extract Text From HTML With String Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bcf432f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<http.client.HTTPResponse at 0x7f6ad9083d90>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 2 :- \n",
    "url=\"http://olympus.realpython.org/profiles/poseidon\"\n",
    "page=urlopen(url)\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "927aff17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      "<head>\n",
      "<title >Profile: Poseidon</title>\n",
      "</head>\n",
      "<body bgcolor=\"yellow\">\n",
      "<center>\n",
      "<br><br>\n",
      "<img src=\"/static/poseidon.jpg\" />\n",
      "<h2>Name: Poseidon</h2>\n",
      "<br><br>\n",
      "Favorite animal: Dolphin\n",
      "<br><br>\n",
      "Favorite color: Blue\n",
      "<br><br>\n",
      "Hometown: Sea\n",
      "</center>\n",
      "</body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "html_bytes=page.read()\n",
    "html=html_bytes.decode('utf-8')\n",
    "print(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b588f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<head>\n",
      "<title >Profile: Poseidon\n"
     ]
    }
   ],
   "source": [
    "start_index=html.find(\"<title>\")+len(\"<title>\")\n",
    "end_index=html.find(\"</title>\")\n",
    "title = html[start_index:end_index]\n",
    "print(title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "33fc23c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profile: Poseidon\n"
     ]
    }
   ],
   "source": [
    "# Extracting title without html tags using Regular Expressions. \n",
    "import re\n",
    "pattern = \"<title.*?>.*?</title.*?>\"\n",
    "match_results = re.search(pattern, html, re.IGNORECASE)\n",
    "title = match_results.group()\n",
    "title = re.sub(\"<.*?>\", \"\", title) # Remove HTML tags\n",
    "\n",
    "print(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea5ea02",
   "metadata": {},
   "source": [
    "### Use an HTML Parser for Web Scraping in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "decc5b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in /home/unnathi/anaconda3/lib/python3.7/site-packages (4.11.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/unnathi/anaconda3/lib/python3.7/site-packages (from beautifulsoup4) (2.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "861d5f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "url=\"http://olympus.realpython.org/profiles/dionysus\"\n",
    "page=urlopen(url)\n",
    "html=page.read().decode('utf-8')\n",
    "soup=BeautifulSoup(html,\"html.parser\") # Creates a BeautifulSoup object and assigns it to soup variable\n",
    "# BeautifulSoup() - takes two arguments - first arg 'html' string to be parsed, second arg 'html.parser' \n",
    "# tells the object which parser to use behind the scenes. \"html.parser\" represents Python’s built-in HTML parser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4209b670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Profile: Dionysus      Name: Dionysus  Hometown: Mount Olympus  Favorite animal: Leopard   Favorite Color: Wine    \n"
     ]
    }
   ],
   "source": [
    "print(soup.get_text().replace(\"\\n\",\" \")) # get_text() - removes all html tags and returns only text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fe74944e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<img src=\"/static/dionysus.jpg\"/>, <img src=\"/static/grapes.png\"/>]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('img')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6038973d",
   "metadata": {},
   "outputs": [],
   "source": [
    "image1,image2= soup.find_all('img') # Output are instances of Tag object provided by BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "90b3833f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'img'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Each Tag object has a .name property that returns a string containing the HTML tag type:\n",
    "image1.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8fb7a51d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/static/dionysus.jpg'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image1[\"src\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a3fb37cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>Profile: Dionysus</title>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Certain tags in HTML documents can be accessed by properties of the Tag object.\n",
    "soup.title # gives the title tag "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "eda61d0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Profile: Dionysus'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.title.string # gives only the string in title tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "81e1adbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title =  All Profiles\n",
      "\n",
      " <html>\n",
      " <head>\n",
      "  <title>\n",
      "   All Profiles\n",
      "  </title>\n",
      " </head>\n",
      " <body bgcolor=\"yellow\">\n",
      "  <center>\n",
      "   <br/>\n",
      "   <br/>\n",
      "   <h1>\n",
      "    All Profiles:\n",
      "   </h1>\n",
      "   <br/>\n",
      "   <br/>\n",
      "   <h2>\n",
      "    <a href=\"/profiles/aphrodite\">\n",
      "     Aphrodite\n",
      "    </a>\n",
      "    <br/>\n",
      "    <br/>\n",
      "    <a href=\"/profiles/poseidon\">\n",
      "     Poseidon\n",
      "    </a>\n",
      "    <br/>\n",
      "    <br/>\n",
      "    <a href=\"/profiles/dionysus\">\n",
      "     Dionysus\n",
      "    </a>\n",
      "   </h2>\n",
      "  </center>\n",
      " </body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example 3 :-\n",
    "base_url=\"http://olympus.realpython.org\"\n",
    "page=urlopen(base_url+'/profiles')\n",
    "html= page.read().decode('utf-8')\n",
    "soup=BeautifulSoup(html,\"html.parser\")\n",
    "print(\"Title = \",soup.title.string)\n",
    "print(\"\\n\",soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e13dcf90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a href=\"/profiles/aphrodite\">Aphrodite</a>,\n",
       " <a href=\"/profiles/poseidon\">Poseidon</a>,\n",
       " <a href=\"/profiles/dionysus\">Dionysus</a>]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d705fbf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://olympus.realpython.org/profiles/aphrodite\n",
      "http://olympus.realpython.org/profiles/poseidon\n",
      "http://olympus.realpython.org/profiles/dionysus\n"
     ]
    }
   ],
   "source": [
    "for link in soup.find_all(\"a\"):\n",
    "    link_url = base_url + link[\"href\"]\n",
    "    print(link_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "783eb48e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting MechanicalSoup\n",
      "  Downloading MechanicalSoup-1.2.0-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: lxml in /home/unnathi/anaconda3/lib/python3.7/site-packages (from MechanicalSoup) (4.9.1)\n",
      "Requirement already satisfied: beautifulsoup4>=4.7 in /home/unnathi/anaconda3/lib/python3.7/site-packages (from MechanicalSoup) (4.11.1)\n",
      "Requirement already satisfied: requests>=2.22.0 in /home/unnathi/anaconda3/lib/python3.7/site-packages (from MechanicalSoup) (2.28.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/unnathi/anaconda3/lib/python3.7/site-packages (from beautifulsoup4>=4.7->MechanicalSoup) (2.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/unnathi/anaconda3/lib/python3.7/site-packages (from requests>=2.22.0->MechanicalSoup) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/unnathi/anaconda3/lib/python3.7/site-packages (from requests>=2.22.0->MechanicalSoup) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/unnathi/anaconda3/lib/python3.7/site-packages (from requests>=2.22.0->MechanicalSoup) (2022.9.24)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/unnathi/anaconda3/lib/python3.7/site-packages (from requests>=2.22.0->MechanicalSoup) (1.26.11)\n",
      "Installing collected packages: MechanicalSoup\n",
      "Successfully installed MechanicalSoup-1.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install MechanicalSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9cfe3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
