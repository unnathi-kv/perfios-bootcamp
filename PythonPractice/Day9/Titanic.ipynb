{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74310d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# filter warnings that can be ignored\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "data = pd.read_csv('titanic.csv')\n",
    "data.head()\n",
    "# It returns a number of rows and columns in a dataset.\n",
    "training_set.shape\n",
    "# It returns column headings.\n",
    "training_set.columns\n",
    "#It returns a number of null values in each column.\n",
    "training_set.isnull().sum()\n",
    "\n",
    "# Dropping of columns\n",
    "# In this step, we are going to drop columns with the least priority. The column such as\n",
    "# ‘PassengerId’ and ‘Ticket’ comes under this category. Use drop() to drop the columns.\n",
    "\n",
    "#dropping ticket column\n",
    "training_set.drop(['Ticket','PassengerId'], 1, inplace=True)\n",
    "\n",
    "training_set.info()\n",
    "\n",
    "# ‘Cabin’: Though Cabin column has 687 missing values, when you see carefully, it has a unique character \n",
    "# at the beginning which denotes the deck number, therefore, we are going to create a column named Deck\n",
    "# to extract this information, which may be used later in our prediction.\n",
    "\n",
    "def assignDeckValue(CabinCode):\n",
    "    if pd.isnull(CabinCode):\n",
    "        category = 'Unknown'\n",
    "    else:\n",
    "        category = CabinCode[0]\n",
    "    return category\n",
    "  \n",
    "Deck = np.array([assignDeckValue(cabin) for cabin in training_set['Cabin'].values])\n",
    "\n",
    "training_set = training_set.assign(Deck = Deck)\n",
    "\n",
    "training_set\n",
    "\n",
    "#‘ParCh’ and ‘SibSp’ are the details related to family size, so let’s derive a new column named ‘Size of the Family’.\n",
    "training_set['FamilySize'] = training_set['SibSp'] + training_set['Parch'] + 1\n",
    "\n",
    "# ‘Name’: Instead of dropping right away, from the Name of the Passenger, we need to get only their Title\n",
    "# Using expression pattern to extract the Title of the passenger\n",
    "\n",
    "training_set['Title'] = training_set.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "\n",
    "# Changing to common category\n",
    "training_set['Title'] = training_set['Title'].replace(['Dr', 'Rev', 'Col', 'Major', 'Countess', 'Sir', 'Jonkheer', 'Lady', 'Capt', 'Don'], 'Others')\n",
    "training_set['Title'] = training_set['Title'].replace('Ms', 'Miss')\n",
    "training_set['Title'] = training_set['Title'].replace('Mme', 'Mrs')\n",
    "training_set['Title'] = training_set['Title'].replace('Mlle', 'Miss')\n",
    "\n",
    "training_set\n",
    "\n",
    "# Now, let's drop Cabin, Name columns, we have extracted needed information from these two.\n",
    "\n",
    "training_set.drop(['Cabin','Name'],1,inplace=True)\n",
    "\n",
    "training_set\n",
    "\n",
    "#  Handling missing values\n",
    "# ‘Embarked’: Only two rows are missing the values for Embarked column.\n",
    "#  Embarked takes categorical values such as C = Cherbourg; Q = Queenstown; S = Southampton, \n",
    "# here we can simply impute the missing values with most commonly occurred value, which is ‘S’ in this case.\n",
    "\n",
    "# Returns count for each category\n",
    "training_set['Embarked'].value_counts()\n",
    "\n",
    "# Fills null values with 'S'-most common occurence\n",
    "common = 'S'\n",
    "training_set['Embarked']=training_set['Embarked'].fillna('S')\n",
    "\n",
    "# Checking the no of null values now\n",
    "training_set['Embarked'].isnull().sum()\n",
    "\n",
    "#  Encoding categorical features\n",
    "#  Many machine learning algorithms cannot support categorical values without being converted \n",
    "#  to numerical values. Fortunately, the python tools of pandas and sci-kit-learn provide several\n",
    "# approaches to handle this situation.\n",
    "\n",
    "#  Initially, we are just going to map the categorical values into numerical data using map().\n",
    "\n",
    "training_set['Embarked'] = training_set['Embarked'].map({'C':0, 'Q':1, 'S':2})\n",
    "training_set['Sex'] = training_set['Sex'].map({'male':0, 'female':1})\n",
    "training_set['Title'] = training_set['Title'].map({'Master':0,'Miss':1,'Mr':2,'Mrs':3,'Others':4})\n",
    "\n",
    "# Now, let's drop Cabin, Name columns, we have extracted needed information from these two.\n",
    "\n",
    "training_set.drop(['Cabin','Name'],1,inplace=True)\n",
    "\n",
    "training_set\n",
    "\n",
    "# Let’s do one conversion using LabelEncoder() provided by sklearn.preprocessing library.\n",
    "\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "training_set['Deck'] = le.fit_transform(training_set['Deck'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
